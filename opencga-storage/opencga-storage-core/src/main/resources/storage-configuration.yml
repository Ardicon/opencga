---

## CellBase client configuration, this is used mainly when annotating variants
## This can be set up using maven profiles in your .m2/settings.xml
cellbase:
  hosts:      ## 'remote' URL hosts to annotate variants, for example: http://bioinfo.hpc.cam.ac.uk/cellbase/
  - "${OPENCGA.CELLBASE.REST.HOST}"
  version: "${OPENCGA.CELLBASE.VERSION}"
  database:   ## 'local' connection to CellBase MongoDB
    hosts:
    - "${OPENCGA.CELLBASE.DB.HOST}"
    user: "${OPENCGA.CELLBASE.DB.USER}"
    password: "${OPENCGA.CELLBASE.DB.PASSWORD}"
    options:         ## This is intended for database specific options such as --authenticationDatabase in MongoDB
      authenticationDatabase: "${OPENCGA.CELLBASE.DB.AUTHENTICATION_DATABASE}"
      readPreference: "${OPENCGA.CELLBASE.DB.READ_PREFERENCE}"
      enableSSL: false
  preferred: "remote"   ## This accept two values: 'local' and 'remote' to fetch data

## Storage Query Server configuration. When CLI is launched in 'server' mode a RESTful web server
## is launched in the specified port.
server:
  rest:
    port: ${OPENCGA.SERVER.REST.PORT}
    logFile: null
  grpc:
    port: ${OPENCGA.SERVER.GRPC.PORT}
    logFile: null

## Solr Search Configuration
search:
  # List of hosts pointing either to the Solr nodes directly using a complete URL or to the zookeper nodes with HOST:PORT
  #    Example for Solr connection:       http://opencga-solr-01.zone:8983/solr
  #    Example for Zookeeper connection:  opencga-zookeeper-01:2181               <-- Recommended for replicated installations
  hosts:
  - ${OPENCGA.STORAGE.SEARCH.HOST}
  mode: "cloud"
  timeout: ${OPENCGA.STORAGE.SEARCH.TIMEOUT}
  insertBatchSize: 10000

## Clinical database for indexing the pathogenic variants reported.
clinical:
  # List of hosts pointing either to the Solr nodes directly using a complete URL or to the zookeper nodes with HOST:PORT
  #    Example for Solr connection:       http://opencga-solr-01.zone:8983/solr
  #    Example for Zookeeper connection:  opencga-zookeeper-01:2181               <-- Recommended for replicated installations
  hosts:
  - ${OPENCGA.STORAGE.CLINICAL.HOST}    # URL containing host and port, e.g. http://localhost:8983/solr/
  mode: "cloud"
  manager: ${OPENCGA.STORAGE.CLINICAL.MANAGER}
  timeout: ${OPENCGA.STORAGE.CLINICAL.TIMEOUT}
  insertBatchSize: 1000

benchmark:
  numRepetitions: 20           # Number of query repetitions
  concurrency: 5               # Number of concurrent threads
  delay: 100                   # Delay between queries
  connectionType: REST         # Select between REST or DIRECT.
  mode: FIXED                  # Select between FIXED or RANDOM
  databaseName: "opencga"
  rest: "http://localhost:8080/${opencga.war.name}"

io:
  connectors:
#    azure:
#      class: "org.opencb.opencga.storage.core.io.managers.AzureBlobStorageIOConnector"
#      options:
#        accountName: "<accountName>"
#        accountKey: "<accountKey>"

alignment:
  options:
    tools.samtools: "${OPENCGA.INSTALLATION.DIR}/tools/samtools/samtools"
    transform.region_size: 200000
    transform.coverage_chunk_size: 1000
    mean_coverage_size_list: [200, 10000]

variant:
  defaultEngine: "${OPENCGA.STORAGE.DEFAULT_ENGINE}"
  options:
    transform.batch.size: 200
    transform.threads: 4
    transform.format: "avro"
    transform.compression: "gzip"
    transform.fail.on.malformed: false

    load.batch.size: 100
    load.threads: 6
    stats.default-genotype: "0/0"   # Default genotype to be used for calculating stats.
    stats.multiallelic: false       # Include secondary alternates in the variant stats calculation

    query.max_timeout: 30000     #(ms) Max allowed timeout for DBAdaptor operations.
    query.default_timeout: 10000 #(ms) Default timeout for DBAdaptor operations. Only used if none is provided.
    query.limit.default: 1000              # Default limit in GET operations. To be used only if not defined.
    query.limit.max: 5000                  # Maximum limit value in GET operations. If tried to be exceeded, the query will fail.
    query.sample.limit.default: 100        # Default sampleLimit in GET operations. To be used only if not defined.
    query.sample.limit.max: 1000           # Maximum sampleLimit value in GET operations. If tried to be exceeded, the query will fail.

    search.intersect.active: true           # Allow intersect queries with the SearchEngine (Solr)
    search.intersect.always: false          # Force intersect queries
    search.intersect.params.threshold: 3    # Minimum number of QueryParams in the query to intersect

    annotation.batch.size: 100
    annotation.threads: 8
    annotation.file.format: "json"
    annotator: "cellbase"
    annotator.cellbase.exclude: "expression"
    annotator.cellbase.use_cache: true
    annotator.cellbase.imprecise_variants: true # Imprecise variants supported by cellbase (REST only)

  ## The following section defines all available storage engine plugins installed
  engines:
    ## MongoDB Storage Engine
    - id: "mongodb"
      engine: "org.opencb.opencga.storage.mongodb.variant.MongoDBVariantStorageEngine"
      database:
        hosts:
          - "${OPENCGA.STORAGE.VARIANT.DB.HOSTS}"
        user: "${OPENCGA.STORAGE.VARIANT.DB.USER}"
        password: "${OPENCGA.STORAGE.VARIANT.DB.PASSWORD}"
        options:    ## This is intended for database specific options such as --authenticationDatabase in MongoDB
          authenticationDatabase: ${OPENCGA.STORAGE.MONGODB.VARIANT.DB.AUTHENTICATION_DATABASE}
          connectionsPerHost: ${OPENCGA.STORAGE.MONGODB.VARIANT.DB.CONNECTIONS_PER_HOST}
          readPreference: "secondaryPreferred"
      options:
        storage.mongodb.parallel.write: false
        storage.mongodb.stage.parallel.write: false
        storage.mongodb.direct_load.parallel.write: false
        storage.mongodb.merge.parallel.write: false
        storage.mongodb.merge.batch.size: 10 #Number of files to merge directly from first to second collection

    ## Hadoop Storage Engine
    - id: "hadoop"
      engine: "org.opencb.opencga.storage.hadoop.variant.HadoopVariantStorageEngine"
      database:
        hosts:
          - "${OPENCGA.STORAGE.HADOOP.VARIANT.DB.HOSTS}"
        user: "${OPENCGA.STORAGE.HADOOP.VARIANT.DB.USER}"
        password: "${OPENCGA.STORAGE.HADOOP.VARIANT.DB.PASSWORD}"
      options:
        storage.hadoop.hbase.namespace: "${OPENCGA.STORAGE.HADOOP.VARIANT.HBASE.NAMESPACE}"
        storage.hadoop.archive.table.presplit.size: 500
        storage.hadoop.archive.table.compression: "gz"                # Allowed values: none, snappy, gz
        storage.hadoop.archive.table.chunk_size: 1000
        storage.hadoop.archive.table.file_batch_size: 1000
        storage.hadoop.variant.table.presplit.size: 500
        storage.hadoop.variant.table.compression: "snappy"            # Allowed values: none, snappy, gz
        storage.hadoop.sample-index.table.presplit.size: 15
        storage.hadoop.sample-index.table.compression: "snappy"       # Allowed values: none, snappy, gz
        storage.hadoop.annotation-index.table.compression: "snappy"   # Allowed values: none, snappy, gz
        storage.hadoop.pending-annotation.table.compression: "snappy" # Allowed values: none, snappy, gz

        # Batch size for querying phoenix
        storage.hadoop.phoenix.fetch_size: -1

        # Hadoop executable file. Used to lunch MapReduce applications
        storage.hadoop.bin: "hadoop"

        storage.hadoop.mr.jar-with-dependencies: "opencga-storage-hadoop-core-${opencga.version}-jar-with-dependencies.jar"

        # Define the MapReduce job executor.
        storage.hadoop.mr.executor: "system"  # Either "system" or "ssh".

        # Use external hadoop installation. ssh to a hadoop edge node
        storage.hadoop.mr.executor.ssh.host: ""               # Hadoop edge node host name
        storage.hadoop.mr.executor.ssh.user: ""               # Hadoop edge node user name
        storage.hadoop.mr.executor.ssh.key: "~/.ssh/id_rsa"   # Hadoop edge node ssh-key file
        storage.hadoop.mr.executor.ssh.password: ""           # Hadoop edge node password. Only if ssh-key is not present. Requires sshpass to run
        storage.hadoop.mr.executor.ssh.remote_opencga_home:   # Remote opencga home location. Only if different than local location.

        # Increase the ScannerTimeoutPeriod from 60000 (1min) to 300000 (5min) to avoid ScannerTimeoutExceptions
        # See opencb/opencga#352 for more info.
        storage.hadoop.mr.scanner.timeout: 300000


## PENDING
## Cache Configuration
cache:
  host: ${OPENCGA.STORAGE.CACHE.HOST}
  active: true
  serialization: "json"
  slowThreshold: 50
  allowedTypes: "aln,var"
  maxResultSize: 5000
  password: ""